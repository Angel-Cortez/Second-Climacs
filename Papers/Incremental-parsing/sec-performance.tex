\section{Performance of our technique}

The performance of our technique can not be stated as a single figure,
nor even as a function of the size of the buffer, simply because it
depends on several factors such as the exact structure of the buffer
contents and the way the user interacts with that contents.

Despite these difficulties, we can give some indications for certain
important special cases.  We ran these tests on a $4$-core Intel Core
processor clocked at $3.3$GHz, running SBCL version 1.3.11.

\subsection{Parsing with an empty cache}

When a buffer is first created, the cache is empty.  The buffer
contents must then be read, character by character, and the cache must
be created from the contents.

We timed this situation with a buffer containing $10000$ lines of
\commonlisp{} code.  The total time to parse was around $2$ seconds.
This result deserves some clarifications:

\begin{itemize}
\item It is very unusual to have a file of \commonlisp{} code with
  this many lines.  Most files contain less than $2000$ lines, which
  is only $1/5$ of the one in our test case.
\item This result was obtained from a very preliminary version of our
  parser.  In particular, to read a character, several generic
  functions where called, including the \texttt{stream-read-char}
  function of the Gray streams library, and then several others in
  order to access the character in the buffer.  Further optimizations
  are likely to decrease the time spent to read a single character.
\item This situation will happen only when a buffer is initially read
  into the editor.  Even very significant subsequent changes to the
  contents will still preserve large portions of the cache, so that
  the number of characters actually read will only be a tiny fraction
  of the total number of characters in the buffer.
\item All the code was compiled with a value $3$ of the \texttt{debug}
  optimize quality, and with a value of $0$ of the \texttt{speed}
  optimize quality.  We plan to investigate what parts of the code are
  critical for good performance and selectively alter the default
  optimize settings for these parts.
\item This particular case can be handled by having the parser process
  the original stream from which the buffer contents was created,
  rather than giving it the buffer protocol wrapped in a stream
  protocol after the buffer has been filled.  That way, the entire
  overhead of the Gray-stream protocol is avoided altogether.
\end{itemize}

\subsection{Parsing after small modifications}

We measured the time to update the cache of a buffer with 1200 lines
of \commonlisp{} code.  We used several variations on the number of
top-level forms and the size of each top-level form.  Three types of
representative modifications were used, namely inserting/deleting a
constituent character, inserting/deleting left parenthesis, and
inserting/deleting a double quote.  All modifications were made at the
very beginning of the file, which is the worst-case scenario for our
technique.

For inserting and deleting a constituent character, we obtained the
result shown in the table below.  For this benchmark, the performance
is independent of the distribution of forms and sub-forms, and roughly
proportional to the number of lines in the buffer:

\vskip 0.3cm
\begin{tabular}{|r|r|r|}
\hline
forms & form size & time\\
\hline
120 & 10 & 0.14ms\\
80 & 15  & 0.14ms\\
60 & 20  & 0.14ms\\
24 & 100 & 0.23ms\\
36 & 100 & 0.32ms\\
\hline
\end{tabular}
\vskip 0.3cm

For inserting and deleting a left parenthesis, we obtained the
result shown in the table below.  For this benchmark, the performance
is independent of the size of the sub-forms of the top-level forms.
For that reason, the form size is given only in number of lines.
These are the results:

\vskip 0.3cm
\begin{tabular}{|r|r|r|}
\hline
forms & form size & time\\
\hline
120 & 10 & 1.3ms\\
80 & 15  & 1.0ms\\
60 & 20  & 0.5ms\\
40 & 30  & 0.7ms\\
30 & 40  & 0.6ms\\
24 & 50  & 0.5ms\\
12 & 100 & 0.5ms\\
\hline
\end{tabular}
\vskip 0.3cm

As the table shows, the performance is worse for many small top-level
forms, and then the execution time is roughly proportional to the
number of forms.  When the number of top-level forms is small, the
execution time decreases asymptotically to around 0.5ms.
